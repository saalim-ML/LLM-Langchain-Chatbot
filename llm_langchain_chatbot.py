# -*- coding: utf-8 -*-
"""LLM LangChain ChatBot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SYpDYoQ4e9VFHPgEmP_4z9PZnRRknZTs
"""

!pip install -q -U langchain-community

!pip install -q -U langchain-openai

import os
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

os.environ["OPENAI_API_KEY"] = "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"
llm = ChatOpenAI(
    temperature=0,
    model_name="gpt-4o-mini"
)

parser = StrOutputParser()

# from langchain_core.messages import content
# chat_history: list of messages
# message -> role & content

# role: 1. system; 1. user; 2. assistant;

def chat():
  chat_history = [
      ("system","you are a helful chatbot")
  ]

  print("Lnagchain chat bot 'exit' to quit\n")

  while True:
    user_input = input("you: ").strip()

    if user_input.lower() =={"exit","quit"}:
      break

    chat_history.append(("user", user_input))

    prompt = ChatPromptTemplate.from_messages(chat_history)

    chain = prompt | llm | parser

    response = chain.invoke({})

    print(f"bot: {response}\n")

    chat_history.append(("assistant", response))

    print("-"*80)

chat()